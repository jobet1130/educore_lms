name: Backup and Disaster Recovery

permissions:
  contents: read
  actions: read
  security-events: write

on:
  schedule:
    # Daily backup at 1 AM UTC
    - cron: '0 1 * * *'
    # Weekly full backup on Sunday at 2 AM UTC
    - cron: '0 2 * * 0'
  workflow_dispatch:

env:
  BACKUP_RETENTION_DAYS: 30
  REGISTRY: ghcr.io
  IMAGE_NAME: ${{ github.repository }}

jobs:
  # Database backup
  database-backup:
    name: Database Backup
    runs-on: ubuntu-latest

    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
    
    - name: Setup backup directory
      run: |
        mkdir -p backups/database
        echo "Backup directory created"
    
    - name: Set backup variables
      run: |
        ENVIRONMENT="production"
        BACKUP_TYPE="incremental"
        TIMESTAMP=$(date +"%Y%m%d_%H%M%S")
        
        echo "ENVIRONMENT=$ENVIRONMENT" >> $GITHUB_ENV
        echo "BACKUP_TYPE=$BACKUP_TYPE" >> $GITHUB_ENV
        echo "TIMESTAMP=$TIMESTAMP" >> $GITHUB_ENV
        echo "BACKUP_PREFIX=educore-$ENVIRONMENT-db" >> $GITHUB_ENV
        echo "BACKUP_FILE=educore-$ENVIRONMENT-db-$TIMESTAMP.sql.gz" >> $GITHUB_ENV
    
    - name: Install PostgreSQL client
      run: |
        sudo apt-get update
        sudo apt-get install -y postgresql-client-15
    
    - name: Create database backup
      run: |
        # Set database connection based on environment
        case "$ENVIRONMENT" in
          "production")
            DB_HOST="${{ secrets.PROD_DB_HOST }}"
            DB_NAME="${{ secrets.PROD_DB_NAME }}"
            DB_USER="${{ secrets.PROD_DB_USER }}"
            DB_PASSWORD="${{ secrets.PROD_DB_PASSWORD }}"
            ;;
          "uat")
            DB_HOST="${{ secrets.UAT_DB_HOST }}"
            DB_NAME="${{ secrets.UAT_DB_NAME }}"
            DB_USER="${{ secrets.UAT_DB_USER }}"
            DB_PASSWORD="${{ secrets.UAT_DB_PASSWORD }}"
            ;;
          "qa")
            DB_HOST="${{ secrets.QA_DB_HOST }}"
            DB_NAME="${{ secrets.QA_DB_NAME }}"
            DB_USER="${{ secrets.QA_DB_USER }}"
            DB_PASSWORD="${{ secrets.QA_DB_PASSWORD }}"
            ;;
        esac
        
        echo "Creating database backup for $ENVIRONMENT environment"
        
        # Set PostgreSQL password
        export PGPASSWORD="$DB_PASSWORD"
        
        # Create backup based on type
        if [ "$BACKUP_TYPE" = "full" ] || [ "$(date +%u)" = "7" ]; then
          echo "Creating full database backup"
          pg_dump -h "$DB_HOST" -U "$DB_USER" -d "$DB_NAME" \
                  --verbose --clean --if-exists --create \
                  --format=custom | gzip > "$BACKUP_FILE"
        else
          echo "Creating incremental database backup"
          # For incremental, we'll do a full dump but with timestamp
          # In a real scenario, you might use WAL-E or similar for true incremental
          pg_dump -h "$DB_HOST" -U "$DB_USER" -d "$DB_NAME" \
                  --verbose --data-only \
                  --format=custom | gzip > "$BACKUP_FILE"
        fi
        
        # Verify backup file
        if [ -f "$BACKUP_FILE" ] && [ -s "$BACKUP_FILE" ]; then
          echo "✅ Database backup created successfully: $BACKUP_FILE"
          ls -lh "$BACKUP_FILE"
        else
          echo "❌ Database backup failed"
          exit 1
        fi
    
    - name: Store backup locally
      run: |
        echo "Storing backup locally: backups/database/$BACKUP_FILE"
        
        mv "$BACKUP_FILE" "backups/database/$BACKUP_FILE"
        
        # Verify backup file
        if [ -f "backups/database/$BACKUP_FILE" ] && [ -s "backups/database/$BACKUP_FILE" ]; then
          echo "✅ Database backup stored locally"
          ls -lh "backups/database/$BACKUP_FILE"
        else
          echo "❌ Failed to store database backup"
          exit 1
        fi
    
    - name: Create backup metadata
      run: |
        mkdir -p backups/metadata
        cat > backups/metadata/$TIMESTAMP.json << EOF
        {
          "backup_type": "database",
          "environment": "$ENVIRONMENT",
          "timestamp": "$TIMESTAMP",
          "file_name": "$BACKUP_FILE",
          "local_path": "backups/database/$BACKUP_FILE",
          "backup_method": "$BACKUP_TYPE",
          "created_by": "github-actions",
          "workflow_run": "${{ github.run_id }}",
          "commit_sha": "${{ github.sha }}"
        }
        EOF
        
        echo "✅ Backup metadata created"
    
    - name: Clean up old backups
      run: |
        echo "Cleaning up old backups (keeping last $BACKUP_RETENTION_DAYS days)"
        
        # Find and delete backups older than retention period
        find backups/database -name "*.sql.gz" -type f -mtime +$BACKUP_RETENTION_DAYS -delete 2>/dev/null || true
        find backups/metadata -name "*.json" -type f -mtime +$BACKUP_RETENTION_DAYS -delete 2>/dev/null || true
        
        echo "✅ Old backups cleaned up"
    
    - name: Upload backup artifacts
      uses: actions/upload-artifact@v4
      with:
        name: database-backup-${{ env.TIMESTAMP }}
        path: |
          backups/database/${{ env.BACKUP_FILE }}
          backups/metadata/${{ env.TIMESTAMP }}.json
        retention-days: ${{ env.BACKUP_RETENTION_DAYS }}
    
    outputs:
      backup_file: ${{ env.BACKUP_FILE }}
      local_path: backups/database/${{ env.BACKUP_FILE }}

  # Media files backup
  media-backup:
    name: Media Files Backup
    runs-on: ubuntu-latest

    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
    
    - name: Setup media backup directory
      run: |
        mkdir -p backups/media
        echo "Media backup directory created"
    
    - name: Set backup variables
      run: |
        ENVIRONMENT="production"
        TIMESTAMP=$(date +"%Y%m%d_%H%M%S")
        
        echo "ENVIRONMENT=$ENVIRONMENT" >> $GITHUB_ENV
        echo "TIMESTAMP=$TIMESTAMP" >> $GITHUB_ENV
        echo "MEDIA_BACKUP_PREFIX=educore-$ENVIRONMENT-media" >> $GITHUB_ENV
    
    - name: Backup media files locally
      run: |
        # Set source directory based on environment
        case "$ENVIRONMENT" in
          "production")
            SOURCE_DIR="/var/www/educore/media"
            ;;
          "uat")
            SOURCE_DIR="/var/www/educore-uat/media"
            ;;
          "qa")
            SOURCE_DIR="/var/www/educore-qa/media"
            ;;
          *)
            SOURCE_DIR="./static/media"
            ;;
        esac
        
        echo "Backing up media files from $SOURCE_DIR"
        
        # Create media backup archive
        MEDIA_BACKUP_FILE="educore-$ENVIRONMENT-media-$TIMESTAMP.tar.gz"
        
        if [ -d "$SOURCE_DIR" ]; then
          tar -czf "backups/media/$MEDIA_BACKUP_FILE" \
              -C "$(dirname $SOURCE_DIR)" \
              "$(basename $SOURCE_DIR)" \
              --exclude="*.tmp" \
              --exclude="cache/*" \
              --exclude="__pycache__/*"
          
          echo "✅ Media files backup completed: $MEDIA_BACKUP_FILE"
        else
          echo "⚠️ Media directory not found: $SOURCE_DIR (creating empty backup)"
          touch "backups/media/$MEDIA_BACKUP_FILE"
        fi
        
        echo "MEDIA_BACKUP_FILE=$MEDIA_BACKUP_FILE" >> $GITHUB_ENV
    
    - name: Create media backup manifest
      run: |
        # Create manifest of backed up files
        mkdir -p backups/manifests
        
        if [ -f "backups/media/$MEDIA_BACKUP_FILE" ]; then
          tar -tzf "backups/media/$MEDIA_BACKUP_FILE" > "backups/manifests/media-$TIMESTAMP.txt"
          echo "✅ Media backup manifest created"
        else
          echo "⚠️ Media backup file not found"
        fi
    
    - name: Upload media backup artifacts
      uses: actions/upload-artifact@v4
      with:
        name: media-backup-${{ env.TIMESTAMP }}
        path: |
          backups/media/${{ env.MEDIA_BACKUP_FILE }}
          backups/manifests/media-${{ env.TIMESTAMP }}.txt
        retention-days: ${{ env.BACKUP_RETENTION_DAYS }}

  # Configuration backup
  config-backup:
    name: Configuration Backup
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
    
    - name: Setup config backup directory
      run: |
        mkdir -p backups/config
        echo "Configuration backup directory created"
    
    - name: Create configuration backup
      run: |
        ENVIRONMENT="production"
        TIMESTAMP=$(date +"%Y%m%d_%H%M%S")
        CONFIG_BACKUP_FILE="educore-$ENVIRONMENT-config-$TIMESTAMP.tar.gz"
        
        echo "Creating configuration backup for $ENVIRONMENT"
        
        # Create backup of configuration files
        tar -czf "backups/config/$CONFIG_BACKUP_FILE" \
            docker-compose*.yml \
            nginx*.conf \
            .env.example \
            requirements.txt \
            Dockerfile \
            .github/ \
            --exclude='.github/workflows/backup-recovery.yml'
        
        echo "CONFIG_BACKUP_FILE=$CONFIG_BACKUP_FILE" >> $GITHUB_ENV
        echo "✅ Configuration backup completed: $CONFIG_BACKUP_FILE"
    
    - name: Upload config backup artifacts
      uses: actions/upload-artifact@v4
      with:
        name: config-backup-${{ env.TIMESTAMP }}
        path: backups/config/${{ env.CONFIG_BACKUP_FILE }}
        retention-days: ${{ env.BACKUP_RETENTION_DAYS }}

  # Backup verification and testing
  backup-verification:
    name: Backup Verification
    runs-on: ubuntu-latest
    needs: [database-backup]
    if: github.event.schedule == '0 2 * * 0'
    
    services:
      postgres:
        image: postgres:15
        env:
          POSTGRES_PASSWORD: postgres
          POSTGRES_DB: backup_test
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 5432:5432
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
    
    - name: Download backup artifacts
      uses: actions/download-artifact@v4
      with:
        pattern: database-backup-*
        path: ./backups/
    
    - name: Install PostgreSQL client
      run: |
        sudo apt-get update
        sudo apt-get install -y postgresql-client-15
    
    - name: Test backup restore
      run: |
        BACKUP_FILE="${{ needs.database-backup.outputs.backup_file }}"
        
        echo "Testing backup restore: $BACKUP_FILE"
        
        # Find the downloaded backup file
        BACKUP_PATH=$(find ./backups -name "$BACKUP_FILE" -type f | head -1)
        
        if [ -z "$BACKUP_PATH" ] || [ ! -f "$BACKUP_PATH" ] || [ ! -s "$BACKUP_PATH" ]; then
          echo "❌ Backup file not found or empty: $BACKUP_FILE"
          echo "Available files:"
          find ./backups -type f -ls
          exit 1
        fi
        
        echo "✅ Backup file found: $BACKUP_PATH"
        
        # Test restore (to test database)
        export PGPASSWORD=postgres
        
        # Decompress and restore
        gunzip -c "$BACKUP_PATH" | pg_restore -h localhost -U postgres -d backup_test --verbose
        
        # Verify restore
        TABLES=$(psql -h localhost -U postgres -d backup_test -t -c "SELECT count(*) FROM information_schema.tables WHERE table_schema='public';")
        
        if [ "$TABLES" -gt 0 ]; then
          echo "✅ Backup restore test successful - $TABLES tables restored"
        else
          echo "❌ Backup restore test failed - no tables found"
          exit 1
        fi

  # Disaster recovery documentation
  disaster-recovery-docs:
    name: Update DR Documentation
    runs-on: ubuntu-latest
    needs: [database-backup, media-backup, config-backup]
    if: always()
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
    
    - name: Generate disaster recovery report
      run: |
        ENVIRONMENT="production"
        TIMESTAMP=$(date +"%Y-%m-%d %H:%M:%S UTC")
        
        cat > disaster-recovery-report.md << EOF
        # Disaster Recovery Report
        
        **Generated:** $TIMESTAMP  
        **Environment:** $ENVIRONMENT  
        **Workflow Run:** ${{ github.run_id }}  
        
        ## Backup Status
        
        | Component | Status | Details |
        |-----------|--------|----------|
        | Database | ${{ needs.database-backup.result }} | ${{ needs.database-backup.outputs.backup_file }} |
        | Media Files | ${{ needs.media-backup.result }} | S3 sync completed |
        | Configuration | ${{ needs.config-backup.result }} | Config files archived |
        
        ## Recovery Procedures
        
        ### Database Recovery
        1. Download backup artifact from GitHub Actions: \`database-backup-<timestamp>\`
        2. Extract backup file: \`${{ needs.database-backup.outputs.backup_file }}\`
        3. Restore using: \`gunzip -c <backup_file> | pg_restore -h <host> -U <user> -d <database>\`
        
        ### Media Files Recovery
        1. Download media backup artifact from GitHub Actions: \`media-backup-<timestamp>\`
        2. Extract media archive: \`tar -xzf <media_backup_file> -C <target_directory>\`
        
        ### Configuration Recovery
        1. Download config backup artifact from GitHub Actions: \`config-backup-<timestamp>\`
        2. Extract configuration files: \`tar -xzf <config_backup_file>\`
        3. Update environment variables
        4. Restart services
        
        ## RTO/RPO Metrics
        - **Recovery Time Objective (RTO):** 4 hours
        - **Recovery Point Objective (RPO):** 24 hours
        - **Last Successful Backup:** $TIMESTAMP
        
        ## Emergency Contacts
        - DevOps Team: devops@educore.com
        - Database Admin: dba@educore.com
        - Security Team: security@educore.com
        
        ## Next Steps
        1. Verify all backups are accessible
        2. Test restore procedures quarterly
        3. Update disaster recovery plan as needed
        EOF
    
    - name: Upload DR report
      uses: actions/upload-artifact@v4
      with:
        name: disaster-recovery-report-${{ github.run_number }}
        path: disaster-recovery-report.md
        retention-days: 365

  # Notification and monitoring
  backup-notification:
    name: Backup Notification
    runs-on: ubuntu-latest
    needs: [database-backup, media-backup, config-backup, backup-verification]
    if: always()
    
    steps:
    - name: Determine backup status
      run: |
        OVERALL_STATUS="success"
        FAILED_JOBS=""
        
        if [ "${{ needs.database-backup.result }}" = "failure" ]; then
          OVERALL_STATUS="failure"
          FAILED_JOBS="$FAILED_JOBS Database,"
        fi
        
        if [ "${{ needs.media-backup.result }}" = "failure" ]; then
          OVERALL_STATUS="failure"
          FAILED_JOBS="$FAILED_JOBS Media,"
        fi
        
        if [ "${{ needs.config-backup.result }}" = "failure" ]; then
          OVERALL_STATUS="failure"
          FAILED_JOBS="$FAILED_JOBS Configuration,"
        fi
        
        if [ "${{ needs.backup-verification.result }}" = "failure" ]; then
          OVERALL_STATUS="failure"
          FAILED_JOBS="$FAILED_JOBS Verification,"
        fi
        
        echo "OVERALL_STATUS=$OVERALL_STATUS" >> $GITHUB_ENV
        echo "FAILED_JOBS=${FAILED_JOBS%,}" >> $GITHUB_ENV
    
    - name: Create backup failure issue
      if: env.OVERALL_STATUS == 'failure'
      uses: actions/github-script@v6
      with:
        script: |
          const environment = 'production';
          const title = `🚨 Backup Failure - ${environment.toUpperCase()} - ${new Date().toISOString().split('T')[0]}`;
          const body = `
          ## Backup Failure Alert
          
          **Environment:** ${environment}  
          **Workflow Run:** ${{ github.run_id }}  
          **Failed Components:** ${process.env.FAILED_JOBS}  
          
          ### Immediate Actions Required:
          1. Investigate backup failures
          2. Verify backup infrastructure
          3. Ensure data protection compliance
          4. Re-run failed backup jobs
          
          ### Impact:
          - Data protection may be compromised
          - Recovery capabilities affected
          - Compliance requirements at risk
          
          **Priority:** CRITICAL - Resolve within 2 hours
          `;
          
          github.rest.issues.create({
            owner: context.repo.owner,
            repo: context.repo.repo,
            title: title,
            body: body,
            labels: ['backup', 'critical', 'infrastructure']
          });
    
    - name: Send success notification
      if: env.OVERALL_STATUS == 'success'
      run: |
        ENVIRONMENT="production"
        echo "✅ Backup completed successfully for $ENVIRONMENT environment"
        echo "📊 All backup components completed without errors"
        echo "🔒 Data protection and disaster recovery capabilities maintained"